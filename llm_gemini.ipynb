{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro cÃ³digo interactÃºa con Gemini 2.0 Flash, ajustando la temperatura para analizar cÃ³mo varÃ­a la creatividad en las respuestas generadas, permitiÃ©ndonos experimentar con diferentes estilos y enfoques de generaciÃ³n de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA generativa: crea texto, imÃ¡genes, mÃºsica, cÃ³digo, Â¡y mÃ¡s! A diferencia de la IA tradicional, NO solo analiza datos, sino que GENERA contenido NUEVO. Piensa en un artista digital o un escritor fantasma impulsado por IA. ğŸ¤–âœ¨ #inteligenciaartificial #iagenerativa #innovacion\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configurar la API Key\n",
    "API_KEY = \"tu*api\" #la generas aqui https://aistudio.google.com/app/apikey\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Instanciar el modelo Gemini\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# Hacer una pregunta al modelo\n",
    "response = model.generate_content(\"Â¿QuÃ© es la inteligencia artificial generativa, resumilo en un tweet?\")\n",
    "\n",
    "# Mostrar la respuesta\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Metadata de uso: prompt_token_count: 17\n",
      "candidates_token_count: 21\n",
      "total_token_count: 38\n",
      "\n",
      "\n",
      "ğŸ”¹ Temperatura 0.2:\n",
      "Planeta vacÃ­o,\n",
      "Risa de espectro en el espacio,\n",
      "Melmac llama a casa.\n",
      "\n",
      "ğŸ“Š Tokens usados: 38\n",
      "\n",
      "ğŸ” Metadata de uso: prompt_token_count: 17\n",
      "candidates_token_count: 19\n",
      "total_token_count: 36\n",
      "\n",
      "\n",
      "ğŸ”¹ Temperatura 0.5:\n",
      "Planeta vacÃ­o,\n",
      "Risa resonando en el espacio,\n",
      "Melmac espera.\n",
      "\n",
      "ğŸ“Š Tokens usados: 36\n",
      "\n",
      "ğŸ” Metadata de uso: prompt_token_count: 17\n",
      "candidates_token_count: 21\n",
      "total_token_count: 38\n",
      "\n",
      "\n",
      "ğŸ”¹ Temperatura 0.8:\n",
      "Planeta, un sueÃ±o,\n",
      "Risas que eco del vacÃ­o,\n",
      "Zorak estÃ¡ allÃ­.\n",
      "\n",
      "ğŸ“Š Tokens usados: 38\n"
     ]
    }
   ],
   "source": [
    "# Instanciar el modelo con temperatura ajustable\n",
    "def preguntar_gemini(pregunta, temperatura=0.7):\n",
    "    model = genai.GenerativeModel(\n",
    "        \"gemini-2.0-flash\",\n",
    "        generation_config={\"temperature\": temperatura}\n",
    "    )\n",
    "\n",
    "    # Generar respuesta\n",
    "    response = model.generate_content(pregunta)\n",
    "\n",
    "    # Ver estructura de usage_metadata\n",
    "    print(f\"\\nğŸ” Metadata de uso: {response.usage_metadata}\")\n",
    "\n",
    "    # Extraemos correctamente el total de tokens\n",
    "    tokens_usados = getattr(response.usage_metadata, \"total_token_count\", \"No disponible\")\n",
    "\n",
    "    return response.text, tokens_usados\n",
    "\n",
    "# Ejemplo de uso con diferentes temperaturas\n",
    "pregunta = \"Escribe un haiku sobre el fantasma del espacio. Devuelve tan solo el poema.\"\n",
    "\n",
    "for temp in [0.2, 0.5, 0.8]:\n",
    "    respuesta, tokens = preguntar_gemini(pregunta, temp)\n",
    "    print(f\"\\nğŸ”¹ Temperatura {temp}:\")\n",
    "    print(respuesta)\n",
    "    print(f\"ğŸ“Š Tokens usados: {tokens}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
